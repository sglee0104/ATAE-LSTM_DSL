{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install ipdb, nltk, visdom, torchnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipdb\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from c:\\Users\\SEONGGYUN\\ATAE-LSTM\\ATAE-LSTM\\data\\Embedding.ipynb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\SEONGGYUN\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from c:\\Users\\SEONGGYUN\\ATAE-LSTM\\ATAE-LSTM\\data\\AspClas.ipynb\n",
      "importing Jupyter notebook from c:\\Users\\SEONGGYUN\\ATAE-LSTM\\ATAE-LSTM\\models\\ATAE_LSTM.ipynb\n",
      "importing Jupyter notebook from c:\\Users\\SEONGGYUN\\ATAE-LSTM\\ATAE-LSTM\\models\\BasicModule.ipynb\n"
     ]
    }
   ],
   "source": [
    "sys.path.append('C:/Users/SEONGGYUN/ATAE-LSTM/ATAE-LSTM')\n",
    "import Ipynb_importer\n",
    "from config import opt\n",
    "from data.Embedding import Emb\n",
    "from data.AspClas import AspClas\n",
    "from models.ATAE_LSTM import ATAE_LSTM\n",
    "from utils.visualize import Visualizer\n",
    "from config import opt\n",
    "from tqdm import tqdm\n",
    "from random import randint\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t\n",
    "from torch.utils.data import DataLoader\n",
    "from torchnet import meter\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val(model, dataloader):\n",
    "    '''\n",
    "    计算模型在验证集上的准确率等信息\n",
    "    '''\n",
    "    \n",
    "    confusion_matrix = meter.ConfusionMeter(opt.classes)\n",
    "    model.eval()\n",
    "    with t.no_grad():\n",
    "        for step, data in enumerate(dataloader):\n",
    "            sentence, terms, label = data\n",
    "            #if opt.use_cuda:\n",
    "                #sentence, terms, label = sentence.cuda(), terms.cuda(), label.cuda()\n",
    "            score = model(sentence, terms)\n",
    "            confusion_matrix.add(score.data.cpu(), label.data.cpu().squeeze())\n",
    "    model.train()\n",
    "    cm_value = confusion_matrix.value()\n",
    "    accuracy = 100.0 * (cm_value.trace()) / (cm_value.sum())\n",
    "    class_equal_accuracy = (float(cm_value[0][0])/(cm_value[0].sum())\n",
    "        +float(cm_value[1][1])/(cm_value[1].sum())\n",
    "        +float(cm_value[2][2])/(cm_value[2].sum())\n",
    "    ) * 100 / 3\n",
    "    return confusion_matrix, accuracy, class_equal_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\SEONGGYUN\\anaconda3\\envs\\modeling23-2\\lib\\runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"c:\\Users\\SEONGGYUN\\anaconda3\\envs\\modeling23-2\\lib\\runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"c:\\Users\\SEONGGYUN\\anaconda3\\envs\\modeling23-2\\lib\\site-packages\\visdom\\server\\__main__.py\", line 16, in <module>\n",
      "    download_scripts_and_run()\n",
      "  File \"c:\\Users\\SEONGGYUN\\anaconda3\\envs\\modeling23-2\\lib\\site-packages\\visdom\\server\\run_server.py\", line 236, in download_scripts_and_run\n",
      "    main()\n",
      "  File \"c:\\Users\\SEONGGYUN\\anaconda3\\envs\\modeling23-2\\lib\\site-packages\\visdom\\server\\run_server.py\", line 230, in main\n",
      "    eager_data_loading=FLAGS.eager_data_loading,\n",
      "  File \"c:\\Users\\SEONGGYUN\\anaconda3\\envs\\modeling23-2\\lib\\site-packages\\visdom\\server\\run_server.py\", line 55, in start_server\n",
      "    app.listen(port, max_buffer_size=1024**3)\n",
      "  File \"c:\\Users\\SEONGGYUN\\anaconda3\\envs\\modeling23-2\\lib\\site-packages\\tornado\\web.py\", line 2109, in listen\n",
      "    server.listen(port, address)\n",
      "  File \"c:\\Users\\SEONGGYUN\\anaconda3\\envs\\modeling23-2\\lib\\site-packages\\tornado\\tcpserver.py\", line 151, in listen\n",
      "    sockets = bind_sockets(port, address=address)\n",
      "  File \"c:\\Users\\SEONGGYUN\\anaconda3\\envs\\modeling23-2\\lib\\site-packages\\tornado\\netutil.py\", line 161, in bind_sockets\n",
      "    sock.bind(sockaddr)\n",
      "OSError: [WinError 10048] 각 소켓 주소(프로토콜/네트워크 주소/포트)는 하나만 사용할 수 있습니다\n",
      "Setting up a new session...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for scripts.\n",
      "It's Alive!\n"
     ]
    }
   ],
   "source": [
    "!python -m visdom.server\n",
    "vis = Visualizer(opt.env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3044/3044 [00:00<00:00, 429519.31it/s]\n",
      "100%|██████████| 100000/100000 [00:00<00:00, 228082.08it/s]\n",
      "100%|██████████| 100000/100000 [00:06<00:00, 15177.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding : successfully input 100000 pretrained word embeddings while 0 failed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3044/3044 [00:00<00:00, 594803.70it/s]\n"
     ]
    }
   ],
   "source": [
    "# step1 data\n",
    "train_data = AspClas(opt.train_data_root, train=True)\n",
    "test_data = AspClas(opt.train_data_root, train=False, emb=train_data.emb)\n",
    "train_dataloader = DataLoader(\n",
    "    train_data,\n",
    "    opt.batch_size,\n",
    "    shuffle=True,\n",
    "    drop_last = True\n",
    ")\n",
    "test_dataloader = DataLoader(\n",
    "    test_data,\n",
    "    opt.batch_size,\n",
    "    shuffle=False,\n",
    "    drop_last = True\n",
    ")\n",
    "words = train_data.emb._get_words_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step2 configure model\n",
    "model = ATAE_LSTM(emb=train_data.emb)\n",
    "#if opt.use_cuda:\n",
    "    #model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step3 criterion and optimizer\n",
    "if opt.rescaling:\n",
    "    class_weights = t.Tensor([3,4,1]) # weights on every class\n",
    "    #if opt.use_cuda:\n",
    "        #class_weights = class_weights.cuda()\n",
    "else:\n",
    "    class_weights = None\n",
    "criterion = t.nn.CrossEntropyLoss(weight = class_weights)\n",
    "lr = opt.lr\n",
    "optimizer = t.optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr = lr,\n",
    "    weight_decay = opt.weight_decay\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step4 meters\n",
    "loss_meter = meter.AverageValueMeter()\n",
    "confusion_matrix = meter.ConfusionMeter(opt.classes)\n",
    "previous_loss = 1e100\n",
    "best_val_accuracy = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_attention(model, words, test_dataloader=None, sentence_terms_label=None):\n",
    "    if test_dataloader is not None:\n",
    "        sentence, terms, label = list(test_dataloader)[0]\n",
    "        #if opt.use_cuda:\n",
    "            #sentence, terms, label = sentence.cuda(), terms.cuda(), label.cuda()\n",
    "    else:\n",
    "        (sentence, terms, label) = sentence_terms_label\n",
    "    tokens = [words[i] for i in sentence[0].tolist() if i!=0]\n",
    "    term = [words[i] for i in terms[0].tolist() if i!=0]\n",
    "    score, attention = model(sentence, terms, returnAttention=True)\n",
    "    attention_probs = attention[0][0][:len(tokens)].tolist()\n",
    "    tokens_attention = [(tokens[i], \"%.3f\"%attention_probs[i]) for i in range(len(tokens))]\n",
    "    tqdm.write(str(tokens))\n",
    "    tqdm.write(str(term))\n",
    "    tqdm.write(str(tokens_attention))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [02:15<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'ambience', 'is', 'very', 'romantic', 'and', 'definitely', 'a', 'good', 'place', 'to', 'bring', 'a', 'date', '.']\n",
      "['place']\n",
      "[('the', '0.162'), ('ambience', '0.175'), ('is', '0.102'), ('very', '0.068'), ('romantic', '0.040'), ('and', '0.051'), ('definitely', '0.043'), ('a', '0.037'), ('good', '0.045'), ('place', '0.058'), ('to', '0.061'), ('bring', '0.056'), ('a', '0.039'), ('date', '0.043'), ('.', '0.019')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [02:16<20:29, 136.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['anyway', ',', 'the', 'food', 'is', 'good', ',', 'the', 'price', 'is', 'right', 'and', 'they', 'have', 'a', 'decent', 'wine', 'list', '.']\n",
      "['price']\n",
      "[('anyway', '0.084'), (',', '0.091'), ('the', '0.092'), ('food', '0.170'), ('is', '0.056'), ('good', '0.039'), (',', '0.045'), ('the', '0.053'), ('price', '0.047'), ('is', '0.032'), ('right', '0.021'), ('and', '0.023'), ('they', '0.025'), ('have', '0.023'), ('a', '0.024'), ('decent', '0.041'), ('wine', '0.059'), ('list', '0.049'), ('.', '0.024')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [04:23<20:29, 136.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'ambience', 'is', 'very', 'romantic', 'and', 'definitely', 'a', 'good', 'place', 'to', 'bring', 'a', 'date', '.']\n",
      "['place']\n",
      "[('the', '0.196'), ('ambience', '0.169'), ('is', '0.102'), ('very', '0.067'), ('romantic', '0.045'), ('and', '0.048'), ('definitely', '0.047'), ('a', '0.039'), ('good', '0.043'), ('place', '0.049'), ('to', '0.051'), ('bring', '0.050'), ('a', '0.038'), ('date', '0.037'), ('.', '0.019')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [04:24<17:30, 131.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['one', 'thing', 'i', 'liked', 'about', 'this', 'place', 'is', 'that', 'i', 'never', 'felt', 'rushed', 'or', 'pressured', 'to', 'give', 'up', 'my', 'table', 'ot', 'incoming', 'guests', '.']\n",
      "['table']\n",
      "[('one', '0.148'), ('thing', '0.047'), ('i', '0.050'), ('liked', '0.058'), ('about', '0.030'), ('this', '0.053'), ('place', '0.038'), ('is', '0.023'), ('that', '0.018'), ('i', '0.027'), ('never', '0.023'), ('felt', '0.031'), ('rushed', '0.050'), ('or', '0.028'), ('pressured', '0.060'), ('to', '0.028'), ('give', '0.026'), ('up', '0.022'), ('my', '0.017'), ('table', '0.022'), ('ot', '0.043'), ('incoming', '0.066'), ('guests', '0.059'), ('.', '0.034')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [06:28<17:30, 131.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'ambience', 'is', 'very', 'romantic', 'and', 'definitely', 'a', 'good', 'place', 'to', 'bring', 'a', 'date', '.']\n",
      "['place']\n",
      "[('the', '0.146'), ('ambience', '0.148'), ('is', '0.099'), ('very', '0.070'), ('romantic', '0.053'), ('and', '0.053'), ('definitely', '0.055'), ('a', '0.047'), ('good', '0.048'), ('place', '0.054'), ('to', '0.056'), ('bring', '0.058'), ('a', '0.046'), ('date', '0.044'), ('.', '0.024')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [06:29<14:59, 128.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['be', 'careful', 'before', 'you', 'request', 'extra', 'spice', '.']\n",
      "['spice']\n",
      "[('be', '0.171'), ('careful', '0.115'), ('before', '0.106'), ('you', '0.106'), ('request', '0.127'), ('extra', '0.135'), ('spice', '0.154'), ('.', '0.085')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [08:34<14:59, 128.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'ambience', 'is', 'very', 'romantic', 'and', 'definitely', 'a', 'good', 'place', 'to', 'bring', 'a', 'date', '.']\n",
      "['place']\n",
      "[('the', '0.165'), ('ambience', '0.147'), ('is', '0.096'), ('very', '0.066'), ('romantic', '0.054'), ('and', '0.050'), ('definitely', '0.055'), ('a', '0.046'), ('good', '0.045'), ('place', '0.052'), ('to', '0.053'), ('bring', '0.056'), ('a', '0.045'), ('date', '0.044'), ('.', '0.024')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [08:35<12:44, 127.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['we', 'thought', 'that', 'this', 'place', 'is', 'using', 'too', 'much', 'of', 'msg', 'cooking', 'in', 'the', 'foods', '.']\n",
      "['foods']\n",
      "[('we', '0.113'), ('thought', '0.095'), ('that', '0.069'), ('this', '0.057'), ('place', '0.063'), ('is', '0.060'), ('using', '0.067'), ('too', '0.058'), ('much', '0.051'), ('of', '0.043'), ('msg', '0.042'), ('cooking', '0.062'), ('in', '0.048'), ('the', '0.054'), ('foods', '0.095'), ('.', '0.023')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [10:41<12:44, 127.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'ambience', 'is', 'very', 'romantic', 'and', 'definitely', 'a', 'good', 'place', 'to', 'bring', 'a', 'date', '.']\n",
      "['place']\n",
      "[('the', '0.194'), ('ambience', '0.152'), ('is', '0.092'), ('very', '0.062'), ('romantic', '0.054'), ('and', '0.047'), ('definitely', '0.053'), ('a', '0.044'), ('good', '0.042'), ('place', '0.049'), ('to', '0.050'), ('bring', '0.054'), ('a', '0.043'), ('date', '0.042'), ('.', '0.023')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [10:41<10:36, 127.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['-', 'the', 'bread', 'at', 'the', 'beginning', 'is', 'super', 'tasty', 'and', 'makes', 'you', 'want', 'more', '-', 'the', 'pizza', 'is', 'delicious', 'and', 'comes', 'in', 'personal', 'sizes', ',', 'however', 'be', 'warned', 'that', 'the', 'peter', \"'s\", 'favourite', 'pizza', 'with', 'prosciutto', 'and', 'baby', 'arugula', 'is', 'actually', 'a', 'margarite', 'pizza', 'with', 'cold', 'prosciutto', 'and', 'baby', 'arugula', 'on', 'top', ',', 'like', 'a', 'salad', '.']\n",
      "['margarite', 'pizza', 'with', 'cold', 'prosciutto', 'and', 'baby', 'arugula', 'on', 'top']\n",
      "[('-', '0.025'), ('the', '0.029'), ('bread', '0.028'), ('at', '0.021'), ('the', '0.022'), ('beginning', '0.021'), ('is', '0.020'), ('super', '0.019'), ('tasty', '0.019'), ('and', '0.016'), ('makes', '0.019'), ('you', '0.018'), ('want', '0.018'), ('more', '0.018'), ('-', '0.012'), ('the', '0.017'), ('pizza', '0.020'), ('is', '0.019'), ('delicious', '0.022'), ('and', '0.017'), ('comes', '0.018'), ('in', '0.016'), ('personal', '0.018'), ('sizes', '0.018'), (',', '0.013'), ('however', '0.014'), ('be', '0.016'), ('warned', '0.014'), ('that', '0.016'), ('the', '0.017'), ('peter', '0.015'), (\"'s\", '0.015'), ('favourite', '0.020'), ('pizza', '0.020'), ('with', '0.017'), ('prosciutto', '0.016'), ('and', '0.015'), ('baby', '0.016'), ('arugula', '0.018'), ('is', '0.018'), ('actually', '0.019'), ('a', '0.015'), ('margarite', '0.015'), ('pizza', '0.019'), ('with', '0.017'), ('cold', '0.017'), ('prosciutto', '0.016'), ('and', '0.016'), ('baby', '0.016'), ('arugula', '0.018'), ('on', '0.017'), ('top', '0.016'), (',', '0.012'), ('like', '0.015'), ('a', '0.013'), ('salad', '0.020'), ('.', '0.008')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [12:44<10:36, 127.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'ambience', 'is', 'very', 'romantic', 'and', 'definitely', 'a', 'good', 'place', 'to', 'bring', 'a', 'date', '.']\n",
      "['place']\n",
      "[('the', '0.160'), ('ambience', '0.147'), ('is', '0.091'), ('very', '0.064'), ('romantic', '0.058'), ('and', '0.050'), ('definitely', '0.057'), ('a', '0.048'), ('good', '0.044'), ('place', '0.053'), ('to', '0.053'), ('bring', '0.058'), ('a', '0.046'), ('date', '0.045'), ('.', '0.024')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [12:45<08:23, 125.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['they', 'did', 'not', 'have', 'mayonnaise', ',', 'forgot', 'our', 'toast', ',', 'left', 'out', 'ingredients', '(', 'ie', 'cheese', 'in', 'an', 'omelet', ')', ',', 'below', 'hot', 'temperatures', 'and', 'the', 'bacon', 'was', 'so', 'over', 'cooked', 'it', 'crumbled', 'on', 'the', 'plate', 'when', 'you', 'touched', 'it', '.']\n",
      "['bacon']\n",
      "[('they', '0.039'), ('did', '0.038'), ('not', '0.032'), ('have', '0.033'), ('mayonnaise', '0.026'), (',', '0.017'), ('forgot', '0.019'), ('our', '0.028'), ('toast', '0.021'), (',', '0.016'), ('left', '0.019'), ('out', '0.022'), ('ingredients', '0.030'), ('(', '0.019'), ('ie', '0.020'), ('cheese', '0.026'), ('in', '0.026'), ('an', '0.032'), ('omelet', '0.022'), (')', '0.016'), (',', '0.015'), ('below', '0.024'), ('hot', '0.026'), ('temperatures', '0.020'), ('and', '0.024'), ('the', '0.026'), ('bacon', '0.027'), ('was', '0.028'), ('so', '0.028'), ('over', '0.028'), ('cooked', '0.024'), ('it', '0.023'), ('crumbled', '0.020'), ('on', '0.025'), ('the', '0.027'), ('plate', '0.026'), ('when', '0.027'), ('you', '0.026'), ('touched', '0.022'), ('it', '0.024'), ('.', '0.011')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [14:41<08:23, 125.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'ambience', 'is', 'very', 'romantic', 'and', 'definitely', 'a', 'good', 'place', 'to', 'bring', 'a', 'date', '.']\n",
      "['place']\n",
      "[('the', '0.122'), ('ambience', '0.135'), ('is', '0.091'), ('very', '0.068'), ('romantic', '0.063'), ('and', '0.054'), ('definitely', '0.062'), ('a', '0.052'), ('good', '0.048'), ('place', '0.058'), ('to', '0.058'), ('bring', '0.064'), ('a', '0.051'), ('date', '0.049'), ('.', '0.025')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [14:42<06:08, 122.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['one', 'thing', 'i', 'liked', 'about', 'this', 'place', 'is', 'that', 'i', 'never', 'felt', 'rushed', 'or', 'pressured', 'to', 'give', 'up', 'my', 'table', 'ot', 'incoming', 'guests', '.']\n",
      "['table']\n",
      "[('one', '0.125'), ('thing', '0.059'), ('i', '0.040'), ('liked', '0.050'), ('about', '0.035'), ('this', '0.052'), ('place', '0.039'), ('is', '0.029'), ('that', '0.025'), ('i', '0.026'), ('never', '0.025'), ('felt', '0.036'), ('rushed', '0.042'), ('or', '0.030'), ('pressured', '0.060'), ('to', '0.032'), ('give', '0.034'), ('up', '0.029'), ('my', '0.026'), ('table', '0.027'), ('ot', '0.041'), ('incoming', '0.062'), ('guests', '0.051'), ('.', '0.025')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [16:50<06:08, 122.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'ambience', 'is', 'very', 'romantic', 'and', 'definitely', 'a', 'good', 'place', 'to', 'bring', 'a', 'date', '.']\n",
      "['place']\n",
      "[('the', '0.108'), ('ambience', '0.128'), ('is', '0.091'), ('very', '0.069'), ('romantic', '0.065'), ('and', '0.055'), ('definitely', '0.065'), ('a', '0.053'), ('good', '0.050'), ('place', '0.060'), ('to', '0.060'), ('bring', '0.068'), ('a', '0.053'), ('date', '0.051'), ('.', '0.024')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [16:51<04:09, 124.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'waiters', 'were', 'not', 'attentive', 'except', 'that', 'the', 'bill', 'turned', 'up', 'on', 'the', 'table', 'before', 'we', 'were', 'finished', '.']\n",
      "['waiters']\n",
      "[('the', '0.052'), ('waiters', '0.055'), ('were', '0.059'), ('not', '0.059'), ('attentive', '0.054'), ('except', '0.056'), ('that', '0.054'), ('the', '0.051'), ('bill', '0.054'), ('turned', '0.047'), ('up', '0.051'), ('on', '0.052'), ('the', '0.050'), ('table', '0.050'), ('before', '0.052'), ('we', '0.055'), ('were', '0.055'), ('finished', '0.052'), ('.', '0.043')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [19:28<04:09, 124.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'ambience', 'is', 'very', 'romantic', 'and', 'definitely', 'a', 'good', 'place', 'to', 'bring', 'a', 'date', '.']\n",
      "['place']\n",
      "[('the', '0.108'), ('ambience', '0.125'), ('is', '0.089'), ('very', '0.068'), ('romantic', '0.065'), ('and', '0.055'), ('definitely', '0.067'), ('a', '0.052'), ('good', '0.050'), ('place', '0.062'), ('to', '0.062'), ('bring', '0.070'), ('a', '0.053'), ('date', '0.052'), ('.', '0.022')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [19:29<02:15, 135.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'food', 'inludes', 'famous', 'scrumptious', 'bombay', 'style', 'chaat', 'such', 'as', 'bhelpuri', ',', 'sevpuri', 'and', 'samosa', 'chaats', ',', 'as', 'well', 'as', 'other', 'great', 'indian', 'appetizers', '.']\n",
      "['food']\n",
      "[('the', '0.056'), ('food', '0.075'), ('inludes', '0.062'), ('famous', '0.068'), ('scrumptious', '0.051'), ('bombay', '0.033'), ('style', '0.038'), ('chaat', '0.038'), ('such', '0.039'), ('as', '0.035'), ('bhelpuri', '0.041'), (',', '0.025'), ('sevpuri', '0.033'), ('and', '0.029'), ('samosa', '0.037'), ('chaats', '0.038'), (',', '0.025'), ('as', '0.030'), ('well', '0.032'), ('as', '0.032'), ('other', '0.040'), ('great', '0.030'), ('indian', '0.043'), ('appetizers', '0.060'), ('.', '0.009')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [22:03<02:15, 135.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'ambience', 'is', 'very', 'romantic', 'and', 'definitely', 'a', 'good', 'place', 'to', 'bring', 'a', 'date', '.']\n",
      "['place']\n",
      "[('the', '0.109'), ('ambience', '0.124'), ('is', '0.087'), ('very', '0.067'), ('romantic', '0.064'), ('and', '0.054'), ('definitely', '0.069'), ('a', '0.051'), ('good', '0.049'), ('place', '0.063'), ('to', '0.063'), ('bring', '0.074'), ('a', '0.052'), ('date', '0.052'), ('.', '0.020')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [22:04<00:00, 132.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'waiter', 'actually', 'poured', 'water', 'on', 'my', 'hand', 'and', 'walked', 'away', '.']\n",
      "['waiter']\n",
      "[('the', '0.070'), ('waiter', '0.062'), ('actually', '0.085'), ('poured', '0.072'), ('water', '0.090'), ('on', '0.101'), ('my', '0.104'), ('hand', '0.100'), ('and', '0.102'), ('walked', '0.072'), ('away', '0.088'), ('.', '0.054')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# step5 train\n",
    "\n",
    "# validate and visualize at start\n",
    "val_cm, val_accuracy, class_equal_accuracy = val(model, test_dataloader)\n",
    "vis.plot('val_accuracy', val_accuracy)\n",
    "vis.plot('val_class_equal_accuracy', class_equal_accuracy)\n",
    "vis.plot('lr', lr)\n",
    "vis.log(\"epoch:{epoch},\\nlr:{lr},\\ntrain_cm:{train_cm},\\nval_cm:{val_cm}\".format(\n",
    "    epoch = 0,\n",
    "    val_cm = str(val_cm.value()),\n",
    "    train_cm=str(confusion_matrix.value()),\n",
    "    lr=lr\n",
    "))\n",
    "\n",
    "total_step = 0\n",
    "for epoch in tqdm(range(opt.max_epoch)):\n",
    "    loss_meter.reset()\n",
    "    confusion_matrix.reset()\n",
    "    \n",
    "    for step, (sentence, terms, label) in enumerate(train_dataloader):\n",
    "        \n",
    "        #if opt.use_cuda:\n",
    "            #sentence, terms, label = sentence.cuda(), terms.cuda(), label.cuda()\n",
    "        \n",
    "        score = model(sentence, terms)\n",
    "        loss = criterion(score, label.squeeze())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # meters update and visualize\n",
    "        if opt.use_cuda:\n",
    "            loss_meter.add(loss.data.cpu())\n",
    "            confusion_matrix.add(score.data.cpu(), label.data.cpu().squeeze())\n",
    "        else:\n",
    "            loss_meter.add(loss.data)\n",
    "            confusion_matrix.add(score.data, label.data.squeeze())\n",
    "        if total_step%opt.print_freq == 0:\n",
    "            vis.plot('loss', loss_meter.value()[0])\n",
    "            \"\"\"vis.log(\"score:{score},target:{label}\".format(\n",
    "                score = score,\n",
    "                label = label\n",
    "            ))\"\"\"\n",
    "        total_step += 1\n",
    "        \n",
    "    \n",
    "    # validate and visualize\n",
    "    val_cm, val_accuracy, class_equal_accuracy = val(model, test_dataloader)\n",
    "    \n",
    "    if val_accuracy > best_val_accuracy:\n",
    "        best_val_accuracy = val_accuracy\n",
    "        model.save(acc=\"%.2f\"%val_accuracy)\n",
    "    \n",
    "    vis.plot('train_accuracy', 100.0*confusion_matrix.value().trace()/confusion_matrix.value().sum())\n",
    "    vis.plot('val_accuracy', val_accuracy)\n",
    "    vis.plot('val_class_equal_accuracy', class_equal_accuracy)\n",
    "    vis.plot('lr', lr)\n",
    "    vis.uplog(\"epoch:{},\\nlr:{},\\nval_cm:\\n{}\\n\".format(\n",
    "        epoch,lr,str(val_cm.value())\n",
    "    ).replace(\"\\n\", \"<br>\"))\n",
    "    \n",
    "    # update learning rate\n",
    "    if loss_meter.value()[0].item() >= previous_loss and lr>opt.lr_min:\n",
    "        lr = lr * opt.lr_decay\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "    previous_loss = loss_meter.value()[0]\n",
    "    if epoch-1 % 100 == 0:\n",
    "        opt.lr_min *= 2/3\n",
    "    \"\"\"\n",
    "    lr = opt.lr * (np.cos(np.pi*(epoch/opt.max_epoch))+1)/2\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "    \"\"\"\n",
    "    if epoch%1 == 0:   ### 원래 50으로 나눔 ####\n",
    "        print_attention(model, words, test_dataloader=test_dataloader)\n",
    "        print_attention(model, words, sentence_terms_label = (sentence, terms, label))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
