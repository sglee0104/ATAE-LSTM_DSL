{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#coding:utf8\n",
    "import os\n",
    "from torch.utils import data\n",
    "import numpy as np\n",
    "import xml.etree.ElementTree as ET\n",
    "import torch as t\n",
    "from nltk.tokenize import word_tokenize\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from C:/Users/SEONGGYUN/ATAE-LSTM/ATAE-LSTM\\data\\Embedding.ipynb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\SEONGGYUN\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('C:/Users/SEONGGYUN/ATAE-LSTM/ATAE-LSTM')\n",
    "import Ipynb_importer\n",
    "from config import opt\n",
    "from data.Embedding import Emb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "                string word =dict=> int index =t.nn.Embedding=> t.Tensor<br>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AspClas(data.Dataset):\n",
    "    \n",
    "    def __init__(self, root=opt.train_data_root, train=True, test=False, emb=None):\n",
    "      \n",
    "        # temporary list to save string format data\n",
    "        # free after init\n",
    "        self.raw_cases = []\n",
    "        # list to save tensor format data\n",
    "        # used when __getitem__() is called\n",
    "        self.cases = []\n",
    "        \n",
    "        # dictionary used to transform polarity\n",
    "        self.polar = {'positive':[2], 'neutral':[1], 'negative':[0]}\n",
    "        \n",
    "        # load root = 'restaurants-trial.xml'\n",
    "        xml = ET.parse(root)\n",
    "        for s in tqdm(xml.findall('sentence')):\n",
    "            if s.find('aspectTerms'):\n",
    "                text = s.find('text').text\n",
    "                asps = s.find('aspectTerms').findall('aspectTerm')\n",
    "                for asp in asps: \n",
    "                    if asp.attrib['polarity'] in self.polar:\n",
    "                        self.raw_cases.append((text, asp.attrib['term'], asp.attrib['polarity']))\n",
    "        \n",
    "        # division\n",
    "        if test:\n",
    "            pass\n",
    "        elif train:\n",
    "            self.raw_cases = self.raw_cases[:int(0.7*len(self.raw_cases))]\n",
    "        else:\n",
    "            self.raw_cases = self.raw_cases[int(0.7*len(self.raw_cases)):]\n",
    "        \n",
    "        \"\"\"\n",
    "        # shuffle\n",
    "        np.random.seed(100)\n",
    "        self.raw_cases = np.random.permutation(self.raw_cases)\n",
    "        \"\"\"\n",
    "        # dataloader already has this function\n",
    "        \n",
    "        \n",
    "        if emb is None:\n",
    "            self.emb = Emb()\n",
    "        else:\n",
    "            self.emb = emb\n",
    "        \n",
    "        # transform\n",
    "        self._addall2emb_()\n",
    "        self.transform()\n",
    "        \n",
    "        return\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        '''\n",
    "        sentence-term-polarity\n",
    "        '''\n",
    "        return self.cases[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.cases)\n",
    "    \n",
    "    def _addall2emb_(self):\n",
    "        for (raw_text, raw_term, raw_polarity) in self.raw_cases:\n",
    "            self.emb._add_word_(raw_text)\n",
    "            self.emb._add_word_(raw_term)\n",
    "        return\n",
    "    \n",
    "    def transform(self):\n",
    "        '''\n",
    "        transform the strings into word index\n",
    "        transform the polar into one-hot of classes\n",
    "        '''\n",
    "        \n",
    "        # refresh self.cases\n",
    "        self.cases = []\n",
    "        \n",
    "        # transform\n",
    "        for (raw_text, raw_term, raw_polarity) in self.raw_cases:\n",
    "            # transform text and term using emb.tokenize\n",
    "            \n",
    "            # text\n",
    "            text_tensor = self.emb.tokenize(raw_text, max_length=opt.max_seq_len)\n",
    "            \n",
    "            # term\n",
    "            term_tensor = self.emb.tokenize(raw_term, max_length=opt.max_terms_len)\n",
    "            \n",
    "            # polarity\n",
    "            polarity_tensor = t.Tensor(self.polar[raw_polarity]).long()\n",
    "            \n",
    "            self.cases.append(\n",
    "                (\n",
    "                    text_tensor,\n",
    "                    term_tensor,\n",
    "                    polarity_tensor\n",
    "                )\n",
    "            )\n",
    "            \n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<?, ?it/s]\n",
      "100%|██████████| 100000/100000 [00:00<00:00, 229026.86it/s]\n",
      "100%|██████████| 100000/100000 [00:06<00:00, 16539.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding : successfully input 100000 pretrained word embeddings while 0 failed\n",
      "(tensor([ 2,  3,  4,  5,  6,  7,  8,  9,  3, 10, 11, 12, 13,  5,  3, 14, 11, 15,\n",
      "        16, 16, 16,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0]), tensor([4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0]), tensor([2]))\n",
      "(tensor([ 2,  3,  4,  5,  6,  7,  8,  9,  3, 10, 11, 12, 13,  5,  3, 14, 11, 15,\n",
      "        16, 16, 16,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0]), tensor([6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0]), tensor([2]))\n",
      "[tensor([[61, 62,  9,  3, 63, 45, 64, 55,  5,  3, 57, 58, 65, 20,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0],\n",
      "        [50, 68,  3, 25, 69,  9, 70, 71, 74, 72,  9,  5, 73, 41, 24, 20,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0]]), tensor([[57,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "        [24,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]]), tensor([[2],\n",
      "        [2]])]\n"
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "    testDataset = AspClas(opt.test_data_root)\n",
    "    testLoader = DataLoader(\n",
    "        testDataset,\n",
    "        batch_size = 2,\n",
    "        shuffle = True\n",
    "    )\n",
    "    print(testDataset[0])\n",
    "    print(testDataset[1])\n",
    "    print(list(testLoader)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
